# ğŸ¯ Taiga Agile Automation with Gemini API

Automatically generate user stories, subtasks, and priority-tag metadata for your Taiga project using Google Gemini LLM â€” all from plain feature ideas. Built for the self-hosted Docker-based Taiga system.

---

## ğŸ“Œ Features

* âœ… Generate Agile-style user stories from plain feature ideas
* âœ… Generate subtasks for each user story
* âœ… Predict tags (e.g., `auth`, `backend`) and priority (`High`, `Medium`, `Low`)
* âœ… Insert stories and tasks directly into your self-hosted Taiga via API
* âœ… Modular and extensible Python codebase

---

## ğŸ› ï¸ Tech Stack

| Tool               | Purpose                                                  |
| ------------------ | -------------------------------------------------------- |
| **Taiga (Docker)** | Agile project management platform                        |
| **Docker Compose** | Container orchestration to run Taiga locally             |
| **Python**         | Automation logic and API calls                           |
| **Gemini API**     | LLM used to convert features into user stories and tasks |
| **dotenv**         | Environment variable management                          |
| **requests**       | REST API client for Python                               |
| **WSL/Linux Environment**       | Operating System                               |

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/taiga-task-automation.git
cd taiga-task-automation
```

### 2. Set Up Taiga Locally with Docker

Make sure Docker is installed and it should support WSL/Linux.

Create a `docker-compose.yml` file (or use the one from Taiga GitHub):

```yaml
version: '3.7'
services:
  taiga:
    image: taigaio/taiga-back:latest
    ports:
      - "9000:80"
    environment:
      - TAIGA_SECRET_KEY=randomkey
```

Run Taiga using Docker:

```bash
docker compose up -d
```

Then access Taiga at: [http://localhost:9000](http://localhost:9000)

---

### 3. Setup Python Environment

```bash
python3 -m venv env
source env/bin/activate
pip install -r requirements.txt
```

> Youâ€™ll need `google-generativeai`, `requests`, and `python-dotenv`

---

### 4. Configure `.env` File

Create a `.env` file:

```env
TAIGA_BASE_URL=http://localhost:9000
TAIGA_USERNAME=your-username
TAIGA_PASSWORD=your-password
GEMINI_API_KEY=your-gemini-api-key
PROJECT_SLUG=your-project-slug
```

---

## ğŸ§  How It Works

```text
Feature Idea â†’ Gemini API â†’ User Stories + Subtasks + Tags â†’ Taiga Tasks via API
```

### Sample Flow

1. You input: "Implement user profile editing and password reset features"
2. Gemini generates 3 user stories
3. Each story gets 3 subtasks
4. Tags and priority are predicted
5. All inserted into Taiga project with linkage

---

## ğŸ“‚ Directory Structure

```
taiga_task_automation/
â”œâ”€â”€ main.py
â”œâ”€â”€ .env
â”œâ”€â”€ auth/
â”‚   â””â”€â”€ taiga_auth.py
â”œâ”€â”€ api/
â”‚   â””â”€â”€ create_tasks.py
â”œâ”€â”€ generators/
â”‚   â”œâ”€â”€ task_generator.py
â”‚   â”œâ”€â”€ subtask_generator.py
â”‚   â””â”€â”€ tag_predictor.py
```

---

## ğŸ“¸ Output Example

![Taiga UI Output](output.png)

> The above screenshot shows generated user stories and their linked subtasks in Taiga UI.

---

## ğŸ Running the Pipeline

```bash
python main.py
```

Youâ€™ll see stories and tasks live-updated in Taiga.

---

## ğŸ”§ Optional Enhancements

* Add retry logic for Gemini API
* Batch all LLM prompts per feature to reduce quota usage
* Log all generated content to `automation_log.json`
* Schedule story creation (e.g., once a day)

---

## ğŸ“„ License

MIT License.

---

## ğŸ™‹â€â™‚ï¸ Need Help?

Open an issue or contact the project maintainer.

---
